version: '3.8'

services:
  # Redis - Message broker and result backend for Celery
  redis:
    image: redis:7-alpine
    container_name: sentinel-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

  # Neo4j - Graph database for Knowledge Graph
  neo4j:
    image: neo4j:5-community
    container_name: sentinel-neo4j
    ports:
      - "7474:7474"  # HTTP browser
      - "7687:7687"  # Bolt protocol
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
    environment:
      - NEO4J_AUTH=neo4j/sentinel_password
      - NEO4J_PLUGINS=["apoc"]
      - NEO4J_dbms_memory_heap_initial__size=512m
      - NEO4J_dbms_memory_heap_max__size=1G
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:7474"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Ollama - Local LLM server (optional)
  ollama:
    image: ollama/ollama:latest
    container_name: sentinel-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    # Comment out 'deploy' section if no GPU available

volumes:
  redis_data:
  neo4j_data:
  neo4j_logs:
  ollama_data:
